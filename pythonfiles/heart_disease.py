# -*- coding: utf-8 -*-
"""heart_disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z29a4XdowwgorTje0g9ejKhSVfBCh4Ft
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# loading the heart dataset to a pandas DataFrame
heart_dataset = pd.read_csv('/content/heart.csv')

heart_dataset.info()

heart_dataset.describe()

heart_dataset.isnull().sum()

heart_dataset.head(6)

sns.scatterplot(x='age',y='chol',hue='target',data=heart_dataset)
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(data=heart_dataset.corr(),annot=True)
plt.show()

sns.pairplot(heart_dataset,hue='target')
plt.show()

plt.figure(figsize=(10,8))


sns.boxplot(data=heart_dataset)
plt.show()

heart_dataset.duplicated()

heart_dataset.drop_duplicates(inplace=True)
heart_dataset.duplicated()

heart_dataset.shape

X = heart_dataset.iloc[:,:-1]
X

Y=heart_dataset["target"]
Y

scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns)
X

Y=heart_dataset["target"]
Y

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.4,random_state=179)

X_train

Y_train

from sklearn import metrics
from sklearn.metrics import classification_report

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()





lr.fit(X_train,Y_train)
Y_pred = lr.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
lr.score(X_train,Y_train)*100,lr.score(X_test,Y_test)*100

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Define the hyperparameter configuration space
logreg_params = {
      'penalty': ['l1','l2'],
       'C': [0.01, 0.1, 1, 10],
       'solver': ['liblinear'],
       'max_iter': [100, 200, 500],
                  }






# Grid search with 3-fold cross-validation
lr_grid = GridSearchCV(lr, logreg_params, cv=3, n_jobs=-1)

# Fit the model on training data
lr_grid.fit(X_train, Y_train)

 # Best hyperparameters
print("Best Parameters:", lr_grid.best_params_)
print( lr_grid.best_estimator_)

lr_grid.fit(X_train,Y_train)
Y_pred = lr_grid.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
lr_grid.score(X_train,Y_train)*100,lr_grid.score(X_test,Y_test)*100

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train,Y_train)
Y_pred = knn.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
knn.score(X_train,Y_train)*100,knn.score(X_test,Y_test)*100

#KNN
from sklearn.model_selection import GridSearchCV
knn_params = {
    'n_neighbors': [2,5,7,12,15],
    }
# Grid search with 3-fold cross-validation
Knn = GridSearchCV(knn, knn_params, cv=3)

# Fit the model on training data
Knn.fit(X_train, Y_train)

# Best hyperparameters
print("Best Parameters:", Knn.best_params_)
print( Knn.best_estimator_)

Knn.fit(X_train,Y_train)
Y_pred = Knn.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
Knn.score(X_train,Y_train)*100,Knn.score(X_test,Y_test)*100

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train,Y_train)
Y_pred = dt.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
dt.score(X_train,Y_train)*100,dt.score(X_test,Y_test)*100

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(dt,filled=True)

dt_params = {
      'criterion': ['gini', 'entropy'],
      'splitter': ['best', 'random'],
      'max_depth': [3, 5, 10, 15],
      'max_features': ['sqrt', 'log2']
                  }




dt_grid= GridSearchCV(dt,param_grid = dt_params,cv = 3)
dt_grid.fit(X_train,Y_train)
# Best hyperparameters
print("Best Parameters:", dt_grid.best_params_)
print( dt_grid.best_estimator_)

dt_grid.fit(X_train,Y_train)
Y_pred = dt_grid.predict(X_test)
confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)
print("-"*70)
print("Report")
print("-"*70)
print("Confusion Matrix:")
print(str(confusion_matrix))
target_names = ['without heart disease', 'with heart disease']
acc=(confusion_matrix[0][0] + confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][0]+confusion_matrix[1][1])
print("Accuracy by confusion matrix: "+str(acc))
print("\n")
print(classification_report(Y_test, Y_pred, target_names=target_names))
print("-"*70)
dt_grid.score(X_train,Y_train)*100,dt_grid.score(X_test,Y_test)*100

#58	0	0	100	248	0	0	122	0	1.0	1	0	2
input_data = (58,0,0,100,248,0,0,122,0,1.0,1,0,2)

# change the input data to a numpy array
input_data_as_numpy_array= np.asarray(input_data)

# reshape the numpy array as we are predicting for only on instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = lr_grid.predict(input_data_reshaped)
print(prediction)

if (prediction[0]== 0):
  print('The Person does not have a Heart Disease ‚ù§Ô∏è')
else:
  print('The Person has Heart Disease üíî')

import pickle

filename = 'heart_data.pkl'
pickle.dump(lr_grid, open(filename, 'wb'))